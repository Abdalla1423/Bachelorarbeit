- poetry verwendet statt env
- google fragen wegen credits, gemini, openai, together.ai
- google colab über langchain, vllm
- serper fürs erste reichen
- langchain code kopieren und selber anpassen
- datensatz reduzieren
- 2 Modelle reicht (ein API und ein Opensource)
- CREDIBLE, UNRELIABLE OR LEAKED?: EVIDENCE VERIFICATION FOR ENHANCED AUTOMATED FACT-CHECKING --> CREDIBILITY ASSESMENT
--> ANSCHREIBEN WENN ES KEIN MODELL GIBT ODER datensatz (DANN TRAINIEREN) (NATURAL LANGUAGE INFERNENCE)
- spezifizieren reasoning als setting

Wichtig
- SAUBERE FORSCHUNG
- CODE sollte reproduzierbar sein
- Eigenleistung --> fragen
- https://github.com/mever-team/credule-dataset

Premtims question: How can large language models be integrated with and without external knowledge bases to enable automated fact-checking of real-world claims?